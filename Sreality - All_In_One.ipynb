{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sreality - All_In_One\n",
    "## Jirka Zelenka\n",
    "### 12.3.-24.4.2020\n",
    "### Celý projekt = Scraping + Cleaning & Dropping + Vizualizace + All_In_One + PowerBI\n",
    "-----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obsah:\n",
    "* 1) Importování Packagů\n",
    "* 2) Definice všech funkcí\n",
    "* 3) Spuštění Procesu\n",
    "* 4) Analýzy a grafy - TBD\n",
    "* 5) Export do HTML a zaslání na mail  - TBD\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------\n",
    "# 1) Importování Packagů\n",
    "-----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##### Obecné ############\n",
    "import pandas as pd                     # for dataframes' manipulation\n",
    "from pandas import DataFrame            # for creating dataframes\n",
    "import numpy as np                      # for arrays\n",
    "import matplotlib as plt                # for plotting\n",
    "from matplotlib.pyplot import figure    # for saving and changing size of plots\n",
    "\n",
    "from collections import Counter         # for counting elements \n",
    "from datetime import datetime           #for actual date\n",
    "import re                               # !!! relativní Novinka - regular expressions\n",
    "from time import sleep                  # for sleeping (slowing down) inside a function\n",
    "import random                           # for random number (sleeping)\n",
    "import math                             # Round float\n",
    "import time                             # Time measuring\n",
    "import itertools                        # for unlisting nested lists\n",
    "\n",
    "\n",
    "##### Scraping ############\n",
    "import requests                         # for robots check\n",
    "from bs4 import BeautifulSoup           # for parsing\n",
    "from selenium import webdriver          # for browsers control\n",
    "import json                             # for Requests\n",
    "\n",
    "##### GeoPy ############        \n",
    "from geopy.geocoders import Nominatim   # Geolocator   # pip install geopy  \n",
    "from geopy.exc import GeocoderTimedOut  # for Error handling\n",
    "\n",
    "##########################\n",
    "# Zaítm nepoužito:\n",
    "##### Widgets ############\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "from IPython.display import display\n",
    "import os\n",
    "from IPython.display import Image\n",
    "\n",
    "##### Bonus - Hudba ############\n",
    "import winsound                        # for Beep-sounds\n",
    "\n",
    "##### Vizualizace ############\n",
    "import seaborn as sns                  #for cool plots\n",
    "\n",
    "\n",
    "\n",
    "import sys                             # ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------\n",
    "# 2) Definice všech funkcí\n",
    "-----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "################################################################################################################################\n",
    "##############################################   SCRAPING    ###################################################################\n",
    "################################################################################################################################\n",
    "\n",
    "################################################################################################################################  1 = Scraping\n",
    "\n",
    "def get_soup_elements(typ_obchodu = \"prodej\", typ_stavby = \"byty\", pages = 1):  \n",
    "    \n",
    "    browser = webdriver.Chrome()\n",
    "    \n",
    "    url_x = r\"https://www.sreality.cz/hledani\"             \n",
    "    url = url_x + \"/\" +  typ_obchodu + \"/\" +  typ_stavby\n",
    "\n",
    "    browser.get(url) \n",
    "    sleep(random.uniform(1.0, 1.5))\n",
    "    innerHTML = browser.execute_script(\"return document.body.innerHTML\")\n",
    "    soup = BeautifulSoup(innerHTML,'lxml') # \"parser\" ??\n",
    "    \n",
    "    elements = []    \n",
    "    \n",
    "    for link in soup.findAll('a', attrs={'href': re.compile(\"^/detail/\")}):     \n",
    "        link = link.get('href')   \n",
    "        elements.append(link)     \n",
    "    elements = elements[0::2]   \n",
    "\n",
    "    ##########################################\n",
    "    # 3. zjištění počtu listů - mělo by být optional, ale nevadí\n",
    "    ##########################################\n",
    "    records = soup.find_all(class_ ='numero ng-binding')[1].text\n",
    "    records = re.split(r'\\D', str(records))                         \n",
    "    records = \",\".join(records).replace(\",\", \"\")\n",
    "    records = int(records)\n",
    "    max_page = math.ceil(records / 20)   \n",
    "    print(\"----------------\")\n",
    "    print(\"Scrapuji: \" + str(typ_obchodu) + \" \" + str(typ_stavby))\n",
    "    print(\"Celkem inzerátů: \" + str(records))\n",
    "    print(\"Celkem stránek: \" + str(max_page))\n",
    "    \n",
    "    ##########################################\n",
    "    # 4. nastavení počtu stránek  -mělo být víc promakané\n",
    "    ##########################################\n",
    "    if pages == 999:      \n",
    "        pages = max_page\n",
    "    \n",
    "    print(\"Scrapuji (pouze) \" + str(pages) + \" stran.\")\n",
    "    print(\"----------------\")\n",
    "    \n",
    "    ##########################################\n",
    "    # 4. Scrapping zbylých listů - naštěstí v jednom okně\n",
    "    ##########################################    \n",
    "    \n",
    "    for i in range(pages-1):   \n",
    "        i = i+2\n",
    "        \n",
    "        sys.stdout.write('\\r'+ \"Strana \" + str(i-1) + \" = \" + str(round(100*(i-1)/(pages), 2)) + \"% progress. Zbývá cca: \" + str(round(random.uniform(3.4, 3.8)*(pages-(i-1)), 2 )) + \" sekund.\")    # Asi upravím čas, na rychlejším kabelu v obýváku je to občas i tak 3 sec :O\n",
    "\n",
    "        url2 = url + \"?strana=\" + str(i)\n",
    "        browser.get(url2)\n",
    "\n",
    "        sleep(random.uniform(1.0, 1.5))\n",
    "\n",
    "        innerHTML = browser.execute_script(\"return document.body.innerHTML\")\n",
    "        soup2 = BeautifulSoup(innerHTML,'lxml') \n",
    "        \n",
    "        elements2 = []\n",
    "        \n",
    "        for link in soup2.findAll('a', attrs={'href': re.compile(\"^/detail/prodej/\")}):  \n",
    "            link = link.get('href') \n",
    "            elements2.append(link)  \n",
    "   \n",
    "        elements2 = elements2[0::2]  \n",
    "        \n",
    "        elements = elements + elements2\n",
    "    \n",
    "    browser.quit()   \n",
    "    \n",
    "    return elements\n",
    "\n",
    "################################################################################################################################  2 = Získání URLS\n",
    "def elements_and_ids(x):\n",
    "    \n",
    "    elements = pd.DataFrame({\"url\":x})\n",
    "\n",
    "    def get_id(x):\n",
    "        x = x.split(\"/\")[-1]\n",
    "        return x\n",
    "\n",
    "    elements[\"url_id\"] = elements[\"url\"].apply(get_id)\n",
    "    \n",
    "    len1 = len(elements)\n",
    "    #Přidáno nově, v tuto chvíli odmažu duplikáty a jsem v pohodě a šetřím si čas dál.\n",
    "    elements = elements.drop_duplicates(subset = [ \"url\", \"url_id\"], keep = \"first\", inplace = False)   \n",
    "    len2 = len(elements)                                                                             \n",
    "                                                                                                      \n",
    "    print(\"-- Vymazáno \" + str(len1-len2) + \" záznamů kvůli duplikaci.\")\n",
    "    return elements\n",
    "\n",
    "################################################################################################################################  3 = získání Souřadnic, Ceny a Popisu = z JSON\n",
    "def get_coords_price_meters(x):\n",
    "    \n",
    "    url = \"https://www.sreality.cz/api/cs/v2/estates/\" + str(x)\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    byt = json.loads(response.text, encoding = 'UTF-8')                                \n",
    "    try:\n",
    "        coords = (byt[\"map\"][\"lat\"], byt[\"map\"][\"lon\"])\n",
    "    except:\n",
    "        coords = (0.01, 0.01)\n",
    "    try:\n",
    "        price = byt[\"price_czk\"][\"value_raw\"] \n",
    "    except:\n",
    "        price = -1\n",
    "        \n",
    "    try:\n",
    "        description = byt[\"meta_description\"]\n",
    "    except:\n",
    "        description = -1\n",
    "    \n",
    "    return coords, price, description\n",
    "\n",
    "\n",
    "# Severní Šířka = latitude\n",
    "# výchoDní / zápaDní Délka = longitude\n",
    "\n",
    "def latitude(x):\n",
    "    x = str(x).split()[0][1:8]\n",
    "    return x\n",
    "\n",
    "def longitude(x):\n",
    "    x = str(x).split()[1][0:7]\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "################################################################################################################################  4 = Prodej + Dům + Pokoje = z URL\n",
    "def characteristics(x):\n",
    "    x = x.split(\"/\")\n",
    "    buy_rent = x[2]\n",
    "    home_house = x[3]\n",
    "    rooms = x[4]\n",
    "    \n",
    "    return buy_rent, home_house, rooms\n",
    "\n",
    "################################################################################################################################  5 =  Plocha z Popisu- VYLEPŠENO\n",
    "\n",
    "# Upravenopro čísla větší než 1000 aby je to vzalo\n",
    "# Zároveň to už nebere Dispozice, Atpyický atd.\n",
    "\n",
    "def plocha(x):\n",
    "    try:\n",
    "        metry = re.search(r'\\s[12]\\s\\d{3}\\s[m]', x)[0] # SPecificky popsáno: Začíná to mezerou, pak 1 nebo 2, pak mezera, pak tři čísla, mezera a pak \"m\"\n",
    "        metry = metry.split()[0] + metry.split()[1]     # Separuju Jedničku + stovky metrů, bez \"m\"\n",
    "    except:\n",
    "        try:\n",
    "            metry = re.search(r'\\s\\d{2,3}\\s[m]', x)[0]  #Mezera, pak 1-3 čísla, mezera a metr\n",
    "            metry = metry.split()[0]                    # Separuju čísla, bez \"m\"\n",
    "        except:\n",
    "            metry = -1\n",
    "    return metry\n",
    "\n",
    "\n",
    "################################################################################################################################  6 = Adresy z předešlých inzerátů a short_coords\n",
    "\n",
    "def short_coords(x):\n",
    "    \"\"\"\n",
    "    x = x.astype(str)   # Bylo potřeba udělat string - ale Tuple se blbě převádí - vyřešil jsem uložením a načtením skrz excel\n",
    "    \"\"\"\n",
    "    \n",
    "    x1 = re.split(r'\\W+', x)[1] + \".\"+re.split(r'\\W+', x)[2]\n",
    "    x1 = round(float(x1), 4)\n",
    "\n",
    "    x2 = re.split(r'\\W+', x)[3] + \".\"+re.split(r'\\W+', x)[4]\n",
    "    x2 = round(float(x2), 4)\n",
    "\n",
    "    return (x1, x2)\n",
    "\n",
    "#############################\n",
    "\n",
    "def adress_old(x):  # Napmapuje až 80 % Adres z předešlých inzerátů\n",
    "\n",
    "    adresy = pd.read_excel(\"Adresy.xlsx\")\n",
    "    adresy = adresy[[\"oblast\", \"město\", \"okres\", \"kraj\", \"url_id\", \"short_coords\"]]\n",
    "    \n",
    "    #Nejlepší napárování je toto:\n",
    "    # porovnáno Inner a Left minus řádky s NaNs a funguje stejně)\n",
    "    \n",
    "    x.short_coords = x.short_coords.astype(str)   # Nově asi musím přidat toto - získat string na souřadnice, protože v Načteném adresáři je mám už taky jako string\n",
    "    data = pd.merge(x, adresy, on=[\"short_coords\", \"url_id\"], how = \"left\")  #upraveno matchování na url_ID + short_coords, je to tak iv Adresáří, je to jednoznačné, jsou tam unikátní. \n",
    "                                                                            # Pokud si v dalším kroku dostáhnu ke starému url_id a k nové coords ještě novou adresu, tak pak se mi uloží do Adresáře nová kombiance ID + short_coord a je to OK\n",
    "                                                                             # Viz funkce\"update_databáze_adres() kde je totéž info\n",
    "            \n",
    "    print(\"-- Počet doplněných řádků je: \" + str(len(data[~data.kraj.isna()])) + \", počet chybějících řádků je: \"   + str(len(data[data.kraj.isna()])))\n",
    "    \n",
    "    return data\n",
    "\n",
    "################################################################################################################################ 7 = Adresy - zbývající přes GeoLocator\n",
    "\n",
    "def adress_new(x):\n",
    "\n",
    "# Pozn. - je to random, závislost rychlosti na user_agent, i na format_string se nepovedlo potvrdit - ale dokumentace user-agent uvíádí jako povinnost\n",
    "# Naopak timeout na 20s a na None a zpátky mi nepomohl s rychlostí, ale minimálně zrušil Errory - None záleží na verzi geopy !! viz dokumentace\n",
    "# Nejvíc podezřívám Wifi vs. kabel - 3 sec -> 1/3 sec, skoro vždy -> Ano, kabel v pokoji = 3-20s na záznam, kabel v obýváku = 0.25s na záznam !!!!!!!!!!!!!!!!§\n",
    "# Problém s Too many requests se \"spraví přes noc\", kdyžtak - nebo viz stackoverflow - nastavit user-agent (https://stackoverflow.com/questions/22786068/how-to-avoid-http-error-429-too-many-requests-python)\n",
    "  \n",
    "    geolocator = Nominatim(timeout = 20, user_agent = \"JZ_Sreality\")   # Pomohlo změnit jméno, proti \"Error 403\" !!        \n",
    "    location = geolocator.reverse(x.strip(\"())\"))   \n",
    "                                                    # Reverse samotné znamená obrácené vyhleádvání = souřadnice -> Adresa\n",
    "     \n",
    "    try:\n",
    "        oblast  = location[0].split(\",\")[-7]\n",
    "    except:\n",
    "        oblast  = -1\n",
    "    try:\n",
    "        město = location[0].split(\",\")[-6]\n",
    "    except:\n",
    "        město  = -1\n",
    "    try:\n",
    "        okres = location[0].split(\",\")[-5]\n",
    "    except:\n",
    "        okres  = -1\n",
    "    try:\n",
    "        kraj = location[0].split(\",\")[-4]  \n",
    "    except:\n",
    "        kraj  = -1       \n",
    "    \n",
    "    time.sleep(0.5)\n",
    "    return oblast, město, okres, kraj\n",
    "\n",
    "##################################################################\n",
    "\n",
    "# Není nutné, půjde i bez toho - když vypustím TIMEOUT - zatím ale nechávám\n",
    "def repeat_adress(x):\n",
    "    try:\n",
    "        x[\"oblast\"], x[\"město\"],  x[\"okres\"] ,  x[\"kraj\"]  = zip(*x['coords'].map(adress_new))\n",
    "    except GeocoderTimedOut:\n",
    "        print(\"Another try\")\n",
    "        x[\"oblast\"], x[\"město\"],  x[\"okres\"] ,  x[\"kraj\"]  = zip(*x['coords'].map(adress_new))\n",
    "\n",
    "\n",
    "################################################################################################################################ 8 = Merging adres\n",
    "\n",
    "def adress_merging(x):\n",
    "\n",
    "    data_new = x.copy()          \n",
    "    bool_series = pd.isnull(data_new.kraj)                                   \n",
    "    data_new = data_new[bool_series]     #subset s chybějícími adresami, už musím mít hotové ADRESS_OLD !!!!     \n",
    "        \n",
    "    # Musím takhle přímo použít na subset, data_new se tím updatuje\n",
    "    # Ideální případ: cca 3561/3 = 1.200s = 20 min bez záseku -> vše chybějící\n",
    "    repeat_adress(data_new)\n",
    "        \n",
    "    # Nakonec jsem zamítl .merge( all columns, how = \"outer\"), kdoví proč to dávalo 7 řádků navíc a tohle je čistší\n",
    "    data_all = pd.concat([x, data_new], join_axes=[x.columns])   \n",
    "    data_all = data_all[~pd.isnull(data_all.kraj)]\n",
    "    data_all = data_all.sort_index()\n",
    "\n",
    "    data = data_all.copy()\n",
    "    \n",
    "    return data\n",
    "\n",
    "################################################################################################################################\n",
    "##############################################   CLEANING    ###################################################################\n",
    "################################################################################################################################\n",
    "\n",
    "################################################################################################################################ 1 = Mezery u Adres\n",
    "\n",
    "############ Mezery před názvy (všeho) a pomlčky doplněné z GeoPy\n",
    "def smaž_mezery(x):\n",
    "    x = re.findall(r'\\w+', str(x))   # Když napíšu tento regex (r'\\w+-?\\w+'), tak bych i zachoval \"pomlčku\", \n",
    "    x = ' '.join(x)                  # ale to já naopak nechci, vyřeším si dvě věci najednou \n",
    "    \n",
    "    return x\n",
    "\n",
    "################################################################################################################################ 2 = Posunutý Okres, Kraj...\n",
    "\n",
    "def kraj_check(x):\n",
    "    x = x.split()[0]\n",
    "    return x\n",
    "\n",
    "\n",
    "def uprav_adresy(x):\n",
    "\n",
    "    x[\"kraj_check\"] = x[\"kraj\"].apply(kraj_check)\n",
    "\n",
    "    # U těch řádků, kde byl okres v názvu kraje posuň všechny tři hodnoty \"doleva\"\n",
    "    x.oblast[x[\"kraj_check\"] == \"okres\"] = x.město[x[\"kraj_check\"] == \"okres\"].copy()\n",
    "    x.město[x[\"kraj_check\"] == \"okres\"] = x.okres[x[\"kraj_check\"] == \"okres\"].copy()\n",
    "    x.okres[x[\"kraj_check\"] == \"okres\"] = x.kraj[x[\"kraj_check\"] == \"okres\"].copy()\n",
    "    x.kraj[x[\"kraj_check\"] == \"okres\"] = -1\n",
    "\n",
    "    # Oříznutý dataset OBCE\n",
    "    obce = pd.read_excel(r\"obce_okresy_kraje.xlsx\")\n",
    "    obce_kus = obce[[\"okres\", \"kraj\"]].copy()\n",
    "\n",
    "    # LEFT Merge by měl přiřadit okresům správné Kraje z df obcí\n",
    "    data = pd.merge(x, obce_kus, on=['okres'], how = \"left\")\n",
    "\n",
    "    # Smazání případných duplikátů\n",
    "    data.drop_duplicates(keep = \"first\", inplace = True)\n",
    "\n",
    "    # Přiřazení nového sloupečku na starý\n",
    "    data.kraj_x[data[\"kraj_check\"] == \"okres\"] = data.kraj_y[data[\"kraj_check\"] == \"okres\"].copy()\n",
    "\n",
    "    # Přejmenování a získání lepších sloupců\n",
    "    data = data.rename(columns={'kraj_x': 'kraj'})\n",
    "    data = data[[\"popis\", \"prodej\", \"dům\", \"pokoje\", \"plocha\", \"oblast\", \"město\", \"okres\", \"kraj\", \"cena\", \"url\", \"url_id\", \"coords\", \"short_coords\", \"lat\", \"lon\"]]  #Doplněno LAT a LON nově\n",
    "\n",
    "    data.reset_index(inplace = True, drop = True)\n",
    "\n",
    "    return data\n",
    "################################################################################################################################ 3 = Počet obyvatel z Excelu (\"obce_okresy_kraje.xlsx\")\n",
    "\n",
    "def počet_obyvatel(x):\n",
    "\n",
    "    obce = pd.read_excel(\"obce_okresy_kraje.xlsx\")\n",
    "    obce_kus = obce[[\"město\", \"okres\", \"kraj\", \"obyvatelé\"]].copy()\n",
    "    data = pd.merge(x, obce_kus ,on = [\"město\", \"okres\", \"kraj\"], how = \"left\")\n",
    "    data.drop_duplicates(keep = \"first\", inplace = True)\n",
    "\n",
    "    return data\n",
    "\n",
    "################################################################################################################################ 4 = Update databáze adres\n",
    "\n",
    "def update_databáze_adres(x):\n",
    "    \n",
    "    adresy = pd.read_excel(\"Adresy.xlsx\")\n",
    "    len1 = len(adresy)\n",
    "    print(\"-- Původní délka adresáře: \" + str(len1))\n",
    "\n",
    "    #Oříznu si data na to, co chci uložit a přidám aktuální datum\n",
    "    data2 = x[[\"oblast\", \"město\", \"okres\", \"kraj\", \"url\", \"url_id\", \"short_coords\"]]  # Odebráno Coords, vznikaly duplikáty zbytečně\n",
    "    data2[\"Datum\"] = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    # Připojím nová data, dropnu duplikáty (mažu odzadu), resetnu indexy, změřím délku\n",
    "    # Přírůstek by měl odpovídat počtu řádků dohledaných přes Geopy minus duplikáty případně\n",
    "    adresy = pd.concat([adresy, data2])\n",
    "    adresy = adresy.drop_duplicates(subset = [ \"url_id\", \"short_coords\"], keep = \"first\", inplace = False)\n",
    "    \n",
    "    ### Nově vloženo: Odebrat shitty adresy - protože jinak jsem -1 kraj dropoval až ve fázi 3  !!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "    adresy = adresy[adresy.short_coords != \"(0.01, 0.01)\"]\n",
    "    \n",
    "    # Změněna logika, dropni všechno kde máš dvojí varianty pro kombinaci url_id + short_coords, protože přesně tohohle se to mapuje a dělá to pak rozdvojení různá. !!\n",
    "    # Jinak ponechává to možnost že mám jedno ID vícekrát s různými short_coords, ale to je možné, nebrání to zpětnému mapování\n",
    "    adresy.reset_index(inplace = True, drop = True)\n",
    "    len2 = len(adresy)\n",
    "    print( \"-- Nová délka adresáře: \" + str(len2) + \", přidáno \"+ str(len2-len1) + \" záznamů. Ukládám do Adresy.xlsx\")\n",
    "\n",
    "    return adresy\n",
    "\n",
    "\n",
    "################################################################################################################################ 5 = Cena na tisíce\n",
    "\n",
    "# Zatím vypnu \n",
    "\"\"\"\n",
    "def cena_tisíce(y):\n",
    "\n",
    "    y[\"cena\"] = y[\"cena\"].apply(lambda x: int(round(x/1000, 0)))\n",
    "\n",
    "    return y\n",
    "\"\"\"\n",
    "################################################################################################################################ 6 = Cena za metr\n",
    "\n",
    "def cena_metr(y):\n",
    "\n",
    "    y[\"cena_metr\"] = y[\"cena\"].astype(int)/y[\"plocha\"].astype(int)\n",
    "    y[\"cena_metr\"] = y[\"cena_metr\"].apply(lambda x: round(x, 1))\n",
    "    \n",
    "    return y\n",
    "\n",
    "################################################################################################################################\n",
    "##############################################   DROPPING    ###################################################################\n",
    "################################################################################################################################\n",
    "\n",
    "################################################################################################################################ 1 = Missing values\n",
    "\n",
    "def missing_values(x):\n",
    "    \n",
    "    data = x.copy()\n",
    "    \n",
    "    print(\"-- Celkem záznamů bez ceny: \"+ str( len(data[data[\"cena\"] == 0]) )   )\n",
    "    print(\"-- Celkem záznamů bez popisu => plochy: \"+ str( len(data[data[\"plocha\"] == -1]) ) )\n",
    "    print(\"-- Celkem záznamů bez okresu a kraje (pouze starší data): \"+ str(len(data[data[\"kraj\"] == \"1\"]))) \n",
    "    # Pokoje by měly být OK\n",
    "    # Obyvatelé taky\n",
    "    # Cena_metr pak už taky\n",
    "    \n",
    "    data = data[data.cena != 0]\n",
    "    data = data[data.plocha != -1]\n",
    "    data = data[data.kraj != \"1\"]\n",
    "    \n",
    "    \n",
    "    return data\n",
    "\n",
    "################################################################################################################################ 2 = Extrémy\n",
    "\n",
    "def extrémy(x):\n",
    "    \n",
    "    data = x.copy()     # Upraveno aby to korespondovalo s Tisíci\n",
    "    \n",
    "    data = data[data.cena > 50000] # Zatím nikdy nebyl byt pod 100.000, resp za 90.000 půl byt\n",
    "    data = data[data.plocha > 10] # Zatím nikdy nebyla plocha pod 12, snad je to rozumný předpoklad\n",
    "    data = data[data.cena_metr < 450000]   # Zatím nikdy nebyla Víc než 360 za metr, jen v jednom chybném zadání rovnou 568 !!\n",
    "    data = data[data.cena_metr > 1000]   #Toto se občas vidí a je to očividná chyba v zadání inzerátu. Viz CHlumec - 376m !! 338.000\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "################################################################################################################################ 3 = Duplikáty\n",
    "\n",
    "def duplikáty(x):\n",
    "    \n",
    "    data =  x.copy()\n",
    "    a = len(data[data.duplicated([ \"popis\", \"prodej\", \"dům\", \"pokoje\", \"plocha\",\"oblast\", \"město\", \"okres\", \"kraj\", \"obyvatelé\", \"cena\", \"cena_metr\", \"coords\", \"short_coords\", \"lat\", \"lon\"],keep= \"first\")]) # Jen různá URL a ID\n",
    "    #display(len(data[data.duplicated([ \"popis\", \"prodej\", \"dům\", \"pokoje\", \"plocha\",\"oblast\", \"město\", \"okres\", \"kraj\", \"obyvatelé\", \"cena\", \"cena_metr\", ],keep= \"first\")]))                  # Ještě různé souřadnice\n",
    "    #display(len(data[data.duplicated([ \"popis\", \"prodej\", \"dům\", \"pokoje\", \"plocha\",\"oblast\", \"město\", \"okres\", \"kraj\", \"obyvatelé\", \"coords\", \"short_coords\"  ],keep= \"first\")]))          # Různé ceny a ceny za metr\n",
    "    #display(len(data[data.duplicated([ \"popis\", \"prodej\", \"dům\", \"pokoje\", \"plocha\",\"oblast\", \"město\", \"okres\", \"kraj\", \"obyvatelé\" ],keep= \"first\")]))                                       #Různé souřadcnie a ještě různé ceny\n",
    "                                                                                                                                                                                        # Tím že povolím různé ceny duplikáty nepřibydou\n",
    "    print(\"-- Počet řádků, které k sobě mají duplikáty (krom url a url_id): \" + str(a))                                                                                                               #Ty bych asi byl ochoten tolerovat, narozdíl od těch 215. -> Zůstanu u varianty a)\n",
    "    data = data.drop_duplicates(subset =[ \"popis\", \"prodej\", \"dům\", \"pokoje\", \"plocha\",\"oblast\", \"město\", \"okres\", \"kraj\", \"obyvatelé\", \"cena\", \"cena_metr\", \"coords\", \"short_coords\", \"lat\", \"lon\" ],keep= \"first\", inplace = False) \n",
    "    #Z dat dropnu duplikáty podle všeho krom url a url_id, nechávám si první záznamy\n",
    "    \n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "################################################################################################################################\n",
    "##############################################   SCRAPING    ###################################################################\n",
    "################################################################################################################################\n",
    "\n",
    "def scrap_all(typ_obchodu = \"prodej\", typ_stavby = \"byty\", pages = 1):\n",
    "    \n",
    "    # Scrapni data - hezky komunikuje = cca 50 min\n",
    "    data = get_soup_elements(typ_obchodu = typ_obchodu, typ_stavby = typ_stavby, pages = pages)\n",
    "    print( \"1/8 Data scrapnuta, získávám URLs.\")\n",
    "    \n",
    "    # 2 = Získání URLS\n",
    "    data = elements_and_ids(data)\n",
    "    data.to_excel(r\"a1_URLs_prodej_byty.xlsx\")\n",
    "    print( \"2/8 Získány URL, nyní získávám Souřadnice, Ceny a Popis - několik minut...\")\n",
    "    \n",
    "    \n",
    "    # 3 = získání Souřadnic, Ceny a Popisu = z JSON\n",
    "    data[\"coords\"], data[\"cena\"], data[\"popis\"] = zip(*data['url_id'].map(get_coords_price_meters))\n",
    "    data[\"lat\"] = data[\"coords\"].apply(latitude)\n",
    "    data[\"lon\"] = data[\"coords\"].apply(longitude)\n",
    "    data.to_excel(r\"a2_Souřadnice_prodej_byty.xlsx\")\n",
    "    print( \"3/8 Získány Souřadnice, Ceny a Popis, nyní získávám informace z URLs.\")\n",
    "   \n",
    "    # 4 = Prodej + Dům + Pokoje = z URL\n",
    "    data[\"prodej\"], data[\"dům\"],  data[\"pokoje\"] = zip(*data['url'].map(characteristics))\n",
    "    print(\"4/8 Získány informace z URLs, nyní získávám informace z popisu.\")\n",
    "    \n",
    "    # 5 =  Plocha z Popisu\n",
    "    data[\"plocha\"] = data['popis'].apply(plocha)\n",
    "    data.to_excel(r\"a3_Popisky_prodej_byty.xlsx\")\n",
    "    print( \"5/8 Získány informace z Popisu, nyní mapuji Adresy z předešlých inzerátů.\")\n",
    "    \n",
    "   \n",
    "    # 6 = Adresy z předešlých inzerátů a short_coords\n",
    "    data = pd.read_excel(r\"a3_Popisky_prodej_byty.xlsx\")   # Abych se vyhnul konverzi TUPLE na STRING, což není triviální, tak si to radši uložím a znova načtu a získám stringy rovnou. Snad mi to nerozbije zbytek\n",
    "    data[\"short_coords\"] = data[\"coords\"].apply(short_coords)\n",
    "    data_upd = adress_old(data)                                # Tady nepotřebuji maping, protože se nesnažím něco nahodit na všechny řádky, ale merguju celé datasety\n",
    "    data = data_upd.copy()\n",
    "    print( \"6/8 Namapovány Adresy z předešlých inzerátů, nyní stahuji nové Adresy - několik minut...\")            # Přidat do printu počet řádků, kolik mám a kolik zbývá v 7. kroku\n",
    "\n",
    "    # 7-8 = Adresy - zbývající přes GeoLocator + Merging\n",
    "\n",
    "    try:                                    # !!! Riskuju že zas něco selže, jako USER- AGENT posledně...\n",
    "        data_upd = adress_merging(data)    #Přidáno TRY pro situace, kdy už mám všechyn adresy z OLD a nejde nic namapovat !\n",
    "        data = data_upd.copy()\n",
    "        data.to_excel(r\"a4_SCRAPED_prodej_byty.xlsx\")\n",
    "        print(\"7+8/8 Získány nové adresy + mergnuto dohromady. Celková délka datasetu: \"+ str(len(data)) + \". Konec Fáze 1.\")\n",
    "    \n",
    "    except:\n",
    "        data.to_excel(r\"a4_SCRAPED_prodej_byty.xlsx\")\n",
    "        print(\"7+8/8 ŽÁDNÉ nové adresy. Celková délka datasetu: \"+ str(len(data)) + \". Konec Fáze 1.\")\n",
    "    \n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "################################################################################################################################\n",
    "##############################################   CLEANING    ###################################################################\n",
    "################################################################################################################################\n",
    "\n",
    "def clean_all(x):\n",
    "    \n",
    "    #data = pd.read_excel(x)   # Pracovní verze s načítáním dat, jinak napojeno na Scrap\n",
    "    data = x.copy()\n",
    "    \n",
    "    print(\"----------------\")\n",
    "    print(\"Počet záznamů před čištěním: \" + str(len(data)))\n",
    "    \n",
    "    \n",
    "    # 1 = Mezery u adres \n",
    "    data[\"oblast\"] = data[\"oblast\"].apply(smaž_mezery)\n",
    "    data[\"město\"] = data[\"město\"].apply(smaž_mezery)\n",
    "    data[\"okres\"] = data[\"okres\"].apply(smaž_mezery)\n",
    "    data[\"kraj\"] = data[\"kraj\"].apply(smaž_mezery)\n",
    "    print(\"1/6 Vymazány mezery před názvy, následuje posouvání rozbitých okresů a krajů\")\n",
    "    \n",
    "    # 2 = Posunutý Okres, Kraj...\n",
    "    data = uprav_adresy(data)\n",
    "    print(\"2/6 Posunuty rozbité okresy a kraje, následuje doplnění počtu obyvatel.\")\n",
    "     \n",
    "    # 3 = Počet obyvatel z Excelu\n",
    "    data = počet_obyvatel(data)\n",
    "    data.to_excel(\"a5_Adresy_a_obyvatele_data_prodej_byty.xlsx\")\n",
    "    print(\"-- Aktuální délka datasetu: \" + str(len(data)))\n",
    "    print(\"3/6 Doplněn počet obyvatel, updatuji databázi adres.\")\n",
    "    \n",
    "    # 4 = Update databáze adres \n",
    "    adresy = update_databáze_adres(data)\n",
    "    adresy.to_excel(r\"Adresy.xlsx\")\n",
    "    print(\"4/6 Databáze Adres updatována. Délka datasetu: \" + str(len(data)) + \" záznamů. Převádím ceny na tisíce\")    \n",
    "\n",
    "    # 5 Cena na tisíce - zatím vypínám kvůli POWER BI\n",
    "    #data = cena_tisíce(data)\n",
    "    print(\"5/6 Ceny NECHCI ABY BYLY převedeny na tisíce. Počítám ceny za metr.\")\n",
    "    \n",
    "    # 6 Cena za metr\n",
    "    data = cena_metr(data)\n",
    "    data[\"datum\"] = datetime.datetime.now().strftime(\"%d.%m.%Y\")   # Nově přidáno kvůli souhrnným datům\n",
    "    data = data[[\"popis\", \"prodej\", \"dům\", \"pokoje\", \"plocha\", \"oblast\", \"město\", \"okres\", \"kraj\", \"obyvatelé\", \"cena\", \"cena_metr\", \"url\", \"url_id\", \"coords\", \"short_coords\", \"lat\", \"lon\", \"datum\"]]\n",
    "    data.to_excel(\"a6_CLEANED_data_prodej_byty.xlsx\")\n",
    "    print(\"6/6 Spočítány ceny za metr. Celková délka datasetu: \"+ str(len(data)) + \". Konec Fáze 2.\")\n",
    "    \n",
    "          \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "################################################################################################################################\n",
    "##############################################   DROPPING    ###################################################################\n",
    "################################################################################################################################\n",
    "\n",
    "def drop_all(x):\n",
    "    \n",
    "    #data = pd.read_excel(x)   # Pracovní verze s načítáním dat, jinak napojeno na Cleaning\n",
    "    data = x.copy()\n",
    "    x = len(data)\n",
    "    print(\"----------------\")\n",
    "    print(\"Počet záznamů před čištěním: \" + str(x))\n",
    "    \n",
    "    \n",
    "    # 1 = Missing Values\n",
    "    data = missing_values(data)\n",
    "    y = len(data)\n",
    "    print(\"1/3 Vymazány chybějící hodnoty (Ceny, Plochy, (Kraje)), celkem \" + str(x-y) + \" řádků. Zbývá \" + str(y) + \" záznamů.\")\n",
    "\n",
    "    # 2 = Extrémy\n",
    "    data = extrémy(data)\n",
    "    z = len(data)\n",
    "    print(\"2/3 Vymazány extrémní hodnoty (Ceny, Plochy, Cena za metr, celkem \" + str(y-z) + \" řádků. Zbývá \" + str(z) + \" záznamů.\")\n",
    "    \n",
    "    # 3 = Duplikáty\n",
    "    data = duplikáty(data)\n",
    "    b = len(data)\n",
    "    data.to_excel(\"a7_DROPPED_data_prodej_byty.xlsx\")\n",
    "    print(\"3/3 Vymazány duplikáty, zbývá \" + str(b) + \" záznamů. Konec Fáze 3.\")\n",
    "    \n",
    "    display(data.head())\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------\n",
    "# 3) Spuštění Procesu\n",
    "-----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Nastaveno na 2 zkušební stránky\n",
    "# pages = 999 spustí všechny stránky\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "data = drop_all(clean_all( scrap_all(typ_obchodu = \"prodej\", typ_stavby = \"byty\", pages = 2)))\n",
    "\n",
    "t2 = time.time()\n",
    "                                     \n",
    "data_all = pd.read_excel(\"data_prodej_byty_souhrn.xlsx\")\n",
    "display(len(data_all))\n",
    "                                    \n",
    "data_new = pd.concat([data_all, data])\n",
    "display(len(data_new))\n",
    "\n",
    "data_new.to_excel(\"data_prodej_byty_souhrn_NEW.xlsx\")\n",
    "\n",
    "t3 = time.time()\n",
    "\n",
    "print(\"První 3 fáze: \" + str(t2-t1))\n",
    "print(\"Souhrnná data: \" + str(t3-t2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.nunique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isin([-1]).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------\n",
    "# 4) Analýzy a grafy - TBD\n",
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------\n",
    "# 5) Export do HTML a zaslání na mail  - TBD\n",
    "-----------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
