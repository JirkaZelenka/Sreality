
-----------------------
## Progress:
##### 12.3.2020 - start
* Nefunguje beautiful soup,
* nefunguje  XML
* ani dlouhý i krátký formáty div / span atd.
* nefunguje ani google na h2 tagy, tři návody  k ničemu

##### 18.3. - D. mě zachránil se Seleniem, zapomněl jsem na scrapping dynamické JS stránky
##### 19.3. - Scrapnuto všech 600 stran, parametr na počet stran, na byt/dům, prodej/pronájem, změněno H2 na celý popisek a scrapp again
##### 20.3. - Cleaning - split jména, 6+ pokojů na metry
##### 21.3. - Cleaning - separace města z lokality, Praha extra, nějaký testovací groupbies, pivot table
###### - poučka 1 - "list of index out of range" nejspíš znamená že indexy neexistují...
###### - poučka 2 - skoro vše se dá rozkouskovat a printnout
##### 22.3. - zkoumání okresů a krajů, pokus o scrape okresů a obcí
##### 23.3. - Wiki - nalezeny kraje, okresy a obce (města i vsi) - už jen scrape
##### 24.3. - Státní správa - vymyšlen scrape a úpravy podle české abecedy!
##### 25.3. - Vzdávám scraping obcí, mám EXCEL od Z. Manuálně vecpáno všechno do Prahy. Stažena fresh data, reakce na airbnb fail? Jinak mám vylepšené groupbys, Median, První ukázka ostatním
##### 27.3. - Čistá data Obce-Okresy_kraje, hrál jsem si s hledáním stringů ve strinzích, geopy od L. + JSON otestováno funkční hledání souřadnic
##### 28.3. - motám se trochu v souřadnicích a pomalém stahování
##### 29.3. - pomalé stahování pokořeno, mám 12.000 souřadnic, JSON upraven na stahování i ceny, upravení detekce adres z loakce souřadnice,odhad stahování adres = 10h
##### 30.3 - pomalý download - mám 6.000/12.000 přes den. Objeveny tony a první znělka z Beepů. Error handling - nekonečný repeat funkce = stažení zbytku přes noc :)
###### - poučka 3 - dlouhé kody kouskuj a ošetři proti erroru, vždycky komentuj proces PRINTy, přidej zvukové efekty, průěbžně ukládej
###### - poučka 4 - schovat všechna data. Pak už jen nové či staré inzeráty spáruju podle názvu (adresa, místnosti, metry) nebo přes coords, cokoliv krom coords_to_adress
##### 31.3. - stáhnuty všechny adresy, upravena datam chybí už jen METRY. Zopakovány základní analýzy na nových datech
##### 1.4. - Staženy všechny plochy za 50 min (po odblokování jejich zpomalovače). Upravena struktura práce. Odstraněny taré sekce analýzy. Udělán kus čištění, např. plochy
###### - poučka 5 - na jeden sloupec = apply(), když má vzniknout víc sloupců tak map() ??
###### - poučka 6 - STRIP(x) odřeže ze stringu znaky X, SPLIT(X) rozseká strink na místech X
##### 2.4. - uděláno čištění měst - celkem 4 problémy, hezky uhlazené, rozhodnutí co dropovat. Už se to blíží....
##### 3.4. - Dokončeno čištění dat, přidání obyvatel, kontroly a Analýza naostro
##### 4.4. - studuji si publikování notebooku, vychytávky, cool barploty, uděláno první PREZI a posláno D. a L. - feedback je SVG obrázky a Cena za metr !
###### poučka 7 - za nehezké sloupečky jde přidat .to_frame()
###### poučka 8 - můžu dělat conditional formatting: .style.applymap(fce)
##### 5.4. - s D. pořešen hezký export do HTML, dále interaktivní skrývání kodových buněk
##### 6.4. PAUZA
##### 7.4. - Jenom duplikáty, rozmýšlení co dropnout
##### 8.4. - opět řeším duplikáty..
##### 9.4. - PAUZA
##### 10.4. - Další scrapping, po 12 dnech, budu moci zkontrolovat ID jestli se na nich staly změny, kolik přibylo, koik ubylo
##### 11.4. - PAUZA
##### 12.4. - Automatizace scrapingu
##### 13.4. - Stažení nových dat + Skoro hotové mapování Coords na již získané adresy
###### poučka 9 - concat je blbé na sloupce, musím mapovat spíš přes merge, nechat jeden sloupec shodně pojmenovaný a ostatní co chci přidat, pak nejsou duplikátní sloupce
##### -
##### 16.4. boj se stahováním nových adres, potíže s připojením, zkoumání parametrů GEOPY
##### 17.4. po mnoha testech nakoenc zůstanu u "kabelu v obýváku", rychlost 8-20x lepší než kabel v ložnici:D
##### 18.4. Udělán další SCrap dat, zásek u JSON - cena a další, obejevena chyba u Pronájem DOmu - stažena jen jedna stránka. Jinak dodělán merge starýcha nových adres a implementace do funkce
##### 19.4. Dodělán Merge Adres, Nové schéma v malování na hezkou návaznost kroků, udělána funkce na update adresáře, dostažen JSON na předvčerejší data, nalezen problém s duplikovanými názvy měst v Adresáři ve dvou formátech
##### 20.4. Adresář očištěn o duplicity Okresů a Krajů, všude odmazány mezery před jmény, upravena funkce Update_Adressy a Map_old_Adres aby ukládala jen unikátní kombiance url_id + short_coords, totéž při loadingu - konečně snad sjednocené, přehledné, bez duplikování. Dokončena Fáze 1 = scrapping včetně testu
##### 21.4. CELANING - udělány adresy, namapován počet obyvatel, updatování databáze včetně správného počtu řádků, žádné špatné mazání duplikátů, Dále Plocha přes regex - zvládá i "1 000", Ceny /1000 a Cena za metr. HOTOVA fáze 2 !!
##### 22.4. Napojení Fáze 1 a Fáze 2, Doupraveny tři staré sety, abych měl stejné typy úprav a sedělo mi to hezky před čištěním. Potlačen potenciální Error u nových adres, TRY kvůli tomu, když už by všechny adresy existovaly a nebylo co mergovat
##### 23.4. UDělána Fáze 3, celkem rozumné odhady na zahození extrémů dle dosavadních standardů, osekány duplikáty tak asi z 90 %, celkové propojení F1-F3. Započat grafy s cenou za metr. Naučl jsem se grafy vedle sebe ,půjdou na cenu + cenu za metr, nebo pro porovnání více datasetů v různých časech
##### 24.4. POWER BI !! Přetaženy data pro dva dny, hraju si s groupby, mapami, Bubble graphem i vývojem medáníů v čase !
##### 25.4. Další hraní s Power BI, mám vlastně komplet grafy co potřebuju.
##### 26.4. Další SCRAP dat, zásek na JSON + nefungují nové adresy - to musím doladit
##### 27.4. Vytváření reprezentativních okomentovaných souborů na GIT
